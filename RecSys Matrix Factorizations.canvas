{
	"nodes":[
		{"id":"106f1db76f8dda0b","type":"text","text":"### UV factorization\n\n#### Data\n$R: (m, n)$ - user-item matrix\n- $m$ - number of users\n- n - number of items\n- $R_{ui}$ - rating given by user u to item i\n\n#### UV factorization:\n$$R \\approx UV^T $$\n- $U: (m, k)$\n- $V: (n, k)$\n- $k \\ll m, n$\n\nOptimization:\n$$\\sum_{u,i \\in \\Omega} (R_{ui}-U_u\n\\cdot V_i) + \\lambda (||U||^2_F + ||V||^2_F) \\to \\min_{U,V}$$\n#### Intuition\n- $U_u$ and $V_i$ are the latent vectors for users and items\n- If we fix $V$, we get $m$ regression problems for users, if we fix $U$, we get $n$ regression problems for items","x":-235,"y":-211,"width":435,"height":751},
		{"id":"40ed04f42e05f837","type":"text","text":"### SVD - Singular value decomposition\n\n#### Data\n$A: (m, n)$\n#### SVD\n$$A = U \\Sigma V^T$$\n- $U: (m, m)$, $UU^T=I_m$ (orthogonal)\n- $\\Sigma: (m, n)$, diagonal with singular values $\\sigma_1 \\geq \\sigma_2 ... \\geq 0$\n- $V: (n, n)$. $VV^T = I_n$ (orthogonal)\n- $\\textrm{rk}A = r$ - number of nonzero $\\sigma_i$\n\n#### Proof of existence (a draft)\n- $A^T A$ - a Gram matrix. Symmetrical, $\\geq 0$. Thus, can be presented in form $A^TA = VDV^T$\n- Diagonal elements of $D$ are non-negative. Thus, $D$ can be presented in form $\\Sigma^T \\Sigma$\n- So, $A = U \\Sigma V^T$, $A^TA = V\\Sigma^T \\Sigma V^T$ $\\Rightarrow$ $U \\Sigma = AV$   \n- $u_i = A v_i / \\sigma_i$, then add the rest of the $U$ vectors to make $U$ orthogonal\n#### Calculation by hand\n[SVD Decomposition](https://www.youtube.com/watch?v=jDJ_xVW0AXY)\n\n$$X = \\begin{pmatrix}  0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0\\end{pmatrix}$$\n$m = 2, n = 4$\n$X^TX = V\\Sigma^T U^T \\cdot U \\Sigma V^T = V \\Sigma^T \\Sigma V^T: (n, n) = (4, 4)$ \n$XX^T = U\\Sigma V^T \\cdot V \\Sigma^T U^T = U \\Sigma \\Sigma^T U^T: (m,m) = (2,2)$ \n\n$$XX^T = \\begin{pmatrix} 2 & 0 \\\\ 0 & 2\\end{pmatrix}, \\ u_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\ \\ u_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$$\n$\\lambda_1 = \\lambda_2 = 2$, $\\sigma_1 = \\sigma_2 = \\sqrt{2}$ \n$$ \\Sigma = \\begin{pmatrix}  \\sqrt{2} & 0 & 0 & 0 \\\\ 0 & \\sqrt{2} & 0 & 0\\end{pmatrix}$$\n$u_i^T X = \\sigma_i v_i^T$, other two vectors \n","x":220,"y":-209,"width":620,"height":1089}
	],
	"edges":[]
}