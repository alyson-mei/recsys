{
	"nodes":[
		{"id":"7d1bf332e33c1fa8","x":-520,"y":-1280,"width":620,"height":340,"type":"text","text":"**Источники сигналов:**\n\n> **История взаимодействий** — последовательность действий пользователя с товарами (просмотры, корзина, покупки). В нашем треке ключевой сигнал — покупки.\n\n> **Атрибуты товара** — табличные, текстовые и визуальные признаки: категория, бренд, цена, материал, описание, эмбеддинги изображений и т.д."},
		{"id":"a620bbd0be337e2d","x":-520,"y":120,"width":800,"height":1440,"type":"text","text":"### Постановка задачи и базовая специфика\n\n**1. Постановка**\n- **Топ-K персональных рекомендаций** для каждого пользователя в категории _apparel_.\n- Задача не «угадать 1 товар», а **составить упорядоченный список**, где важен порядок позиций.\n- На проверке будет **автоматическая метрика качества ранжирования** (скорее всего, что-то вроде NDCG@K, MAP@K, MRR@K).\n\n**2. Источники сигналов**\n- **История взаимодействий** (просмотры, покупки) — основной ресурс.\n- **Атрибуты товара** (категория, бренд, материал, сезон, цена).\n- **Поведенческие признаки** (частота, давность покупок, тренды по пользователю).\n- **Контент** (тексты: названия, описания; изображения — если есть).\n- ==**Холодный старт**== — нужно будет строить рекомендации для новых товаров/пользователей, значит, контентные признаки должны быть в пайплайне\n\n**3. ==Специфика apparel==**\n\n- **Сезонность**: зима → куртки, шапки, шарфы; лето → шорты, сандалии.\n- **Совместимость**: ботинки → носки; платье → сумка.\n- Можно явно моделировать «часто берут вместе» + «схожие стили».\n    \n**4. Масштабируемость**\n\n- Каталог большой → нужно быстро искать похожие товары (Faiss, Annoy, HNSWlib, Milvus).\n- Алгоритм должен выдерживать **инференс на всех пользователях** за разумное время.\n- Протестируй пайплайн на подвыборке, но держи в голове, что финальный прогон будет x100 по объёму.\n\n**5. Разделить решение на два этапа**\n- **Candidate generation** (сузить каталог до 100–300 кандидатов для пользователя).    \n- **Ranking** (отранжировать кандидатов по вероятности покупки).\n- Это позволит держать баланс между качеством и скоростью\n\n**6. Требования к сабмиту**\n- CSV: `user_id, recommendations` — рекомендации в **одной строке через разделитель** (формат уточнят).\n- **Никаких пропусков**, дубликатов или чужих категорий.\n- Итоговый файл должен быть воспроизводим **одной командой**.\n\n**7. Минимизируем ручную магию**\n- Весь код — от загрузки данных до генерации сабмита — в одном воспроизводимом пайплайне.\n- Всё, что можно — параметризуй (пути, K, фильтры).\n- Обязательно: `requirements.txt` или `environment.yml`.\n\n**8. Тесты и валидация**\n- Локально заведи **валидационный сплит** (например, последние N дней как hold-out).\n- Проверяй метрику на валидации **в том же формате, что будет на лидерборде**.\n- Прогоняй финальный пайплайн на подвыборке перед каждым изменением."},
		{"id":"0df8d6391328214b","x":320,"y":120,"width":680,"height":540,"type":"text","text":"### Блок 1\n\n#### 1) Цель этого шага (коротко)\nСобрать **рабочую** систему, которая:\n- генерирует кандидатов для каждого пользователя (candidate set),\n- ранжирует их в топ-K (простая, воспроизводимая формула),\n- даёт базовый офлайн-скор (Recall/ NDCG) и легко масштабируется."},
		{"id":"794f9c4296dd9e7d","x":160,"y":-1020,"width":860,"height":960,"type":"text","text":"### Коллаборативная фильтрация \n\n1\\. **Матрица User-Item** \nМатрица \"пользователь-товар\" с неявными откликами (0/1) \n| Sparse, Implicit feedback\n\n2\\. **User-based и Item-based CF**\n- User-based - ищем соседей пользователя и рекомендуем их покупки\n- Item-based - ищем соседей товара и предлагаем их текущему пользователю\n| Косинусная близость, коэффициент Жаккара\nПрактика: Item-based CF устойчивее и быстрее при большом каталоге\n\n3\\. **Матричная факторизация**\n> **Матричная факторизация** — разложение матрицы «пользователь–товар» на два компактных матрицы эмбеддингов (пользовательских и товарных) так, чтобы их скалярное произведение приближало известные взаимодействия.\n\n> **Латентные факторы** — скрытые признаки (из вкусов пользователя и свойств товара), которые модель выявляет автоматически в процессе факторизации.\n\n**Схема**: обучаем эмбеддинги пользователей и товаров на неявных откликах (например, Weighted Alternating Least Squares). Получаем быстрый скоринг «пользователь·товар» и легко формируем топ-K.\n\nФакторизация даёт хорошее качество при скромном коде и времени, легко индексируется и масштабируется\n\n4\\. **Популярность и co-occurrence как база**\n\n> **Co-occurrence** (совстречаемость) — частота совместных покупок товаров одним пользователем/в близком времени; сигнал комплементарности.\n\nBaseline для старта: «популярные в категории apparel» + «часто покупают вместе» по последним товарам пользователя"},
		{"id":"e71c48767008a6d2","x":760,"y":-1600,"width":860,"height":440,"type":"text","text":"**Два подхода **\n\n> **Коллаборативная фильтрация** — семейство методов, использующих паттерны совместных взаимодействий пользователей и товаров, без явных признаков самих товаров.\n\n**Идея:** «похожие пользователи выбирают похожие товары». Нужна матрица взаимодействий и механика поиска сходства.\n\n> **Контентные рекомендации** — методы, сопоставляющие товары по их признакам (атрибутам, текстам, изображениям) и предлагающие похожие на уже понравившиеся.\n\n**Идея:** «товары похожи по своим признакам, значит один может быть заменой/дополнением другому» — работает даже без истории у конкретного пользователя."},
		{"id":"71a8d7a78e71c0e5","x":1160,"y":-1020,"width":840,"height":960,"type":"text","text":"### Контентные рекомендации\n\n1\\. **Признаки каталога**  \n    Категория, бренд, цена, материал, сезон — формируют **вектор товара**. Кодируем категориальные, нормируем числовые, объединяем в один вектор.\n\n> Таргет-кодирование — замена категориального значения статистикой целевой переменной по этой категории (например, частотой покупки).\n\n2\\. **Тексты**\nНазвания и описания дают семантику: «пуховая куртка», «водонепроницаемые ботинки». Даже простые TF-IDF-мешки слов уже помогают ранжировать похожие товары.\n\n> TF-IDF — способ представить текст как веса слов, повышая значение редких терминов и понижая частые «общие» слова.\n\n3\\. **Визуальные признаки**\nЭмбеддинги изображений учитывают стиль и цвет. Для apparel визуальная близость часто отражает вкус пользователя.\n\n> Эмбеддинг — числовой вектор фиксированной длины, компактно описывающий объект (товар, текст, изображение) с сохранением смысловой близости.\n\n4\\. **Ранжирование по сходству**  \n    Финальный вектор товара = [категориальные эмбеддинги; числовые; текстовые; визуальные]. Для пользователя берём последние N товаров, ищем ближайшие по косинусу и составляем кандидаты.\n#### Как выбирать подход и комбинировать их\n\n- Если **много истории** у пользователей и товаров — CF даст сильный сигнал вкусов.\n- Если **много новых товаров** или атрибуты богаты — контентный метод стабилен и объясним.\n- Лучший практический путь — **гибрид**: контентная часть генерирует кандидатов, CF/факторизация помогает их ранжировать по вероятности покупки.\n\n>"}
	],
	"edges":[
		{"id":"7b2980f814a6ecdd","fromNode":"e71c48767008a6d2","fromSide":"bottom","toNode":"794f9c4296dd9e7d","toSide":"top"}
	]
}