{
	"nodes":[
		{"id":"a620bbd0be337e2d","x":-520,"y":-420,"width":800,"height":1200,"type":"text","text":"### Постановка задачи и базовая специфика\n\n**1. Постановка**\n- **Топ-K персональных рекомендаций** для каждого пользователя в категории _apparel_.\n- Задача не «угадать 1 товар», а **составить упорядоченный список**, где важен порядок позиций.\n- На проверке будет **автоматическая метрика качества ранжирования** (скорее всего, что-то вроде NDCG@K, MAP@K, MRR@K).\n\n**2. Источники сигналов**\n- **История взаимодействий** (просмотры, покупки) — основной ресурс.\n- **Атрибуты товара** (категория, бренд, материал, сезон, цена).\n- **Поведенческие признаки** (частота, давность покупок, тренды по пользователю).\n- **Контент** (тексты: названия, описания; изображения — если есть).\n- ==**Холодный старт**== — нужно будет строить рекомендации для новых товаров/пользователей, значит, контентные признаки должны быть в пайплайне\n\n**3. ==Специфика apparel==**\n\n- **Сезонность**: зима → куртки, шапки, шарфы; лето → шорты, сандалии.\n- **Совместимость**: ботинки → носки; платье → сумка.\n- Можно явно моделировать «часто берут вместе» + «схожие стили».\n    \n**4. Масштабируемость**\n\n- Каталог большой → нужно быстро искать похожие товары (Faiss, Annoy, HNSWlib, Milvus).\n- Алгоритм должен выдерживать **инференс на всех пользователях** за разумное время.\n- Протестируй пайплайн на подвыборке, но держи в голове, что финальный прогон будет x100 по объёму.\n\n**5. Разделить решение на два этапа**\n- **Candidate generation** (сузить каталог до 100–300 кандидатов для пользователя).    \n- **Ranking** (отранжировать кандидатов по вероятности покупки).\n- Это позволит держать баланс между качеством и скоростью\n\n**6. Готовься к строгие требования к сабмиту**\n- CSV: `user_id, recommendations` — рекомендации в **одной строке через разделитель** (формат уточнят).\n- **Никаких пропусков**, дубликатов или чужих категорий.\n- Итоговый файл должен быть воспроизводим **одной командой**."}
	],
	"edges":[]
}